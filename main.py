import io
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
from joblib import load
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier


# --- Page config ---
st.set_page_config(
    page_title="Decision Tree ‚Äì Breast Cancer (Feature Ablation)",
    page_icon="üå≥",
    layout="centered",
)

# --- Constants ---
CSV_FILE = Path("breast_cancer_bd.csv")
TARGET = "Class"
ID_COLS = ["id", "Sample code number"]
ALL_FEATURES = [
    "Clump Thickness", 
    "Uniformity of Cell Size", 
    "Uniformity of Cell Shape",
    "Marginal Adhesion", 
    "Single Epithelial Cell Size", 
    "Bare Nuclei",
    "Bland Chromatin", 
    "Normal Nucleoli", 
    "Mitoses",
]

# =========================
# Helper functions
# =========================
@st.cache_data(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV...")
def load_and_prep_data(csv_path: Path, features: list[str]) -> tuple[pd.DataFrame, pd.Series] | tuple[None, None]:
    """‡πÇ‡∏´‡∏•‡∏î CSV, ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î, ‡∏Ñ‡∏∑‡∏ô X (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡πÅ‡∏•‡∏∞ y (0/1)."""
    if not csv_path.exists():
        return None, None
    try:
        df = pd.read_csv(csv_path, na_values=["?"])
        # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏≠‡∏î‡∏µ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        df = df.drop(columns=[col for col in ID_COLS if col in df.columns], errors="ignore")

        if TARGET not in df.columns:
            st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ '{TARGET}' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV")
            return None, None

        X = df.drop(columns=[TARGET]).copy()

        # ‡∏ó‡∏≥ case-insensitive ‡πÉ‡∏´‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏£‡∏á ALL_FEATURES
        rename_map = {}
        X.columns = [col.strip() for col in X.columns]
        for feat in ALL_FEATURES:
            for col in X.columns:
                if feat.lower() == col.lower():
                    rename_map[col] = feat
                    break
        X = X.rename(columns=rename_map)

        # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ features ‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        for feat in ALL_FEATURES:
            if feat not in X.columns:
                X[feat] = np.nan

        X = X[features].apply(pd.to_numeric, errors="coerce")

        # map target: 2 -> 0 (benign), 4 -> 1 (malignant)
        y = df[TARGET].map({2: 0, 4: 1})

        return X, y
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV: {e}")
        return None, None


def get_model_pipeline(features: list[str]) -> Pipeline:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline (Imputer median + DecisionTree) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å."""
    preprocessor = ColumnTransformer(
        transformers=[("num", SimpleImputer(strategy="median"), features)],
        remainder="drop",
    )
    classifier = DecisionTreeClassifier(
        random_state=42,
        class_weight="balanced",
        criterion="gini",
        max_depth=5,
        min_samples_split=5,
        min_samples_leaf=2,
    )
    return Pipeline([
        ("preprocess", preprocessor),
        ("model", classifier),
    ])


@st.cache_resource(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
def load_model(uploaded_file: bytes | None, features: tuple[str, ...]) -> tuple[Pipeline | None, str]:
    X, y = load_and_prep_data(CSV_FILE, list(features))
    if X is not None and y is not None:
        try:
            model = get_model_pipeline(list(features))
            model.fit(X, y)
            return model, f"trained_from_{CSV_FILE.name}"
        except Exception as e:
            st.error(f"‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å CSV ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
            return None, "no_model"

    return None, "no_model"


def predict_one(model: Pipeline, values: dict, features: list[str], threshold: float) -> tuple[int, float]:
    """‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (robust ‡∏ï‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏≤‡∏¢/‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)"""
    row = {col: values.get(col, np.nan) for col in features}
    df_one = pd.DataFrame([row], columns=features).apply(pd.to_numeric, errors="coerce")

    try:
        proba = float(model.predict_proba(df_one)[0][1])
    except AttributeError:
        try:
            score = float(model.decision_function(df_one)[0])
            proba = 1.0 / (1.0 + np.exp(-score))
        except AttributeError:
            pred_label = int(model.predict(df_one)[0])
            return pred_label, float(pred_label)

    pred_label = 1 if proba >= threshold else 0
    return pred_label, proba


# =========================
# App
# =========================
def main():
    st.title("üå≥ Decision Tree ‚Äì ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á‡πÄ‡∏ï‡πâ‡∏≤‡∏ô‡∏°")

    # Sidebar removed ‚Äî provide sensible defaults so rest of app is unaffected
    selected_features = ALL_FEATURES.copy()
    uploaded_joblib = None
    threshold = 0.5

    # ----- Load/Train model ‡∏ï‡∏≤‡∏°‡∏ä‡∏∏‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå -----
    model, src = load_model(uploaded_joblib.read() if uploaded_joblib else None, tuple(selected_features))
    if model is None:
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå CSV ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        st.stop()

    status_message = "‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î" if "upload" in src else f"‡∏à‡∏≤‡∏Å {CSV_FILE.name}"
    st.success(f"‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ({status_message}) ‚Äî ‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå {len(selected_features)} ‡∏ï‡∏±‡∏ß")

    # ----- ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå (‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) -----
    st.subheader("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå (1‚Äì10)")
    input_values = {}
    cols = st.columns(2)
    for i, feat in enumerate(selected_features):
        with cols[i % 2]:
            # ‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö benign-ish
            if feat == "Clump Thickness":
                default_value = 5
            elif feat == "Single Epithelial Cell Size":
                default_value = 2
            elif feat == "Bland Chromatin":
                default_value = 3
            else:
                default_value = 1
            input_values[feat] = st.number_input(feat, min_value=1, max_value=10, value=default_value, step=1)

    # ----- ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß -----
    if st.button("üîÆ ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå", use_container_width=True):
        pred_label, proba = predict_one(model, input_values, selected_features, threshold)
        result_text = "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á" if pred_label == 1 else "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á"
        (st.error if pred_label == 1 else st.success)(f"**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {result_text}**")
        st.progress(proba)

    # ----- ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• + ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy -----
    with st.expander("üìÑ ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"):
        X, y = load_and_prep_data(CSV_FILE, selected_features)
        if X is None:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy")
        else:
            st.write(f"‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: **{CSV_FILE.name}**")
            st.dataframe(pd.concat([X, y.rename(TARGET)], axis=1), use_container_width=True)

            colA, colB = st.columns(2)
            with colA:
                if st.button("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy (Hold-out 20%) ‚Äî ‡∏ä‡∏∏‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"):
                    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô/‡∏ó‡∏î‡∏™‡∏≠‡∏ö..."):
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42, stratify=y
                        )
                        eval_model = get_model_pipeline(selected_features)
                        eval_model.fit(X_train, y_train)
                        acc = accuracy_score(y_test, eval_model.predict(X_test))
                        st.info(f"**Accuracy (selected features): {acc * 100:.2f}%**")




if __name__ == "__main__":
    main()

